% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sentiment-dl.R
\name{nlp_sentiment_dl}
\alias{nlp_sentiment_dl}
\title{Spark NLP SentimentDLApproach Sentiment detection Deep Learning annotator}
\usage{
nlp_sentiment_dl(
  x,
  input_cols,
  output_col,
  label_col = NULL,
  max_epochs = NULL,
  lr = NULL,
  batch_size = NULL,
  dropout = NULL,
  verbose = NULL,
  threshold = NULL,
  threshold_label = NULL,
  validation_split = NULL,
  enable_output_logs = NULL,
  output_logs_path = NULL,
  uid = random_string("sentiment_dl_")
)
}
\arguments{
\item{x}{A \code{spark_connection}, \code{ml_pipeline}, or a \code{tbl_spark}.}

\item{input_cols}{Input columns. String array.}

\item{output_col}{Output column. String.}

\item{label_col}{If DatasetPath is not provided, this Seq\link{Annotation} type of column should have labeled data per token (string)}

\item{max_epochs}{Maximum number of epochs to train (integer)}

\item{lr}{Initial learning rate (float)}

\item{batch_size}{Batch size for training (integer)}

\item{dropout}{Dropout coefficient (float)}

\item{verbose}{Verbosity level during training (integer)}

\item{threshold}{The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel}

\item{threshold_label}{In case the score is less than threshold, what should be the label. Default is neutral.}

\item{validation_split}{Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off (float)}

\item{enable_output_logs}{whether to enable the TensorFlow output logs (boolean)}

\item{output_logs_path}{path for the output logs}

\item{uid}{A character string used to uniquely identify the ML estimator.}

\item{...}{Optional arguments, see Details.}
}
\value{
The object returned depends on the class of \code{x}.

\itemize{
\item \code{spark_connection}: When \code{x} is a \code{spark_connection}, the function returns an instance of a \code{ml_estimator} object. The object contains a pointer to
a Spark \code{Estimator} object and can be used to compose
\code{Pipeline} objects.

\item \code{ml_pipeline}: When \code{x} is a \code{ml_pipeline}, the function returns a \code{ml_pipeline} with
the NLP estimator appended to the pipeline.

\item \code{tbl_spark}: When \code{x} is a \code{tbl_spark}, an estimator is constructed then
immediately fit with the input \code{tbl_spark}, returning an NLP model.
}

When \code{x} is a \code{spark_connection} the function returns a SentimentDLApproach estimator.
When \code{x} is a \code{ml_pipeline} the pipeline with the SentimentDLApproach added. When \code{x}
is a \code{tbl_spark} a transformed \code{tbl_spark}  (note that the Dataframe passed in must have the input_cols specified).
}
\description{
Multi-class sentiment analysis annotator.
SentimentDL is an annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets
NOTE: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.
NOTE: UniversalSentenceEncoder and SentenceEmbeddings can be used for the inputCol
}
\details{
See \url{https://nlp.johnsnowlabs.com/docs/en/annotators#sentimentdl}
}
