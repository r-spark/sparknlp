% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{nlp_conll_read_dataset}
\alias{nlp_conll_read_dataset}
\title{Transform CoNLL format text file to Spark dataframe}
\usage{
nlp_conll_read_dataset(
  sc,
  path,
  read_as = NULL,
  document_col = NULL,
  sentence_col = NULL,
  token_col = NULL,
  pos_col = NULL,
  conll_label_index = NULL,
  conll_pos_index = NULL,
  conll_text_col = NULL,
  label_col = NULL,
  explode_sentences = NULL
)
}
\arguments{
\item{sc}{a Spark connection}

\item{path}{path to the file to read}

\item{read_as}{Can be LINE_BY_LINE or SPARK_DATASET, with options if latter is used (default LINE_BY_LINE)}

\item{document_col}{name to use for the document column}

\item{sentence_col}{name to use for the sentence column}

\item{token_col}{name to use for the token column}

\item{pos_col}{name to use for the part of speech column}

\item{conll_label_index}{index position in the file of the ner label}

\item{conll_pos_index}{index position in the file of the part of speech label}

\item{conll_text_col}{name to use for the text column}

\item{label_col}{name to use for the label column}

\item{explode_sentences}{boolean whether the sentences should be exploded or not}
}
\value{
Spark dataframe containing the imported data
}
\description{
In order to train a Named Entity Recognition DL annotator, we need to get CoNLL format data as a spark dataframe.
There is a component that does this for us: it reads a plain text file and transforms it to a spark dataset.
See \url{https://nlp.johnsnowlabs.com/docs/en/annotators#conll-dataset}. All the function arguments have defaults.
See \url{https://nlp.johnsnowlabs.com/api/index.html#com.johnsnowlabs.nlp.training.CoNLL} for the defaults.
}
